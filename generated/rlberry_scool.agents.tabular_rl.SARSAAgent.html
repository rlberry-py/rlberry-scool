

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  <meta name="generator" content="Docutils 0.19: https://docutils.sourceforge.io/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0">

  
  <title>rlberry_scool.agents.tabular_rl.SARSAAgent &mdash; rlberry-scool v0.7.3 documentation</title>
  
  <link rel="canonical" href="https://rlberry.readthedocs.io/en/stable/generated/rlberry_scool.agents.tabular_rl.SARSAAgent.html" />

  

  <link rel="stylesheet" href="../_static/css/vendor/bootstrap.min.css" type="text/css" />
  <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
<script id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
<script src="../_static/jquery.js"></script> 
</head>
<body>


<nav id="navbar" class="sk-docs-navbar navbar navbar-expand-md navbar-light bg-light py-0">
  <div class="container-fluid sk-docs-container px-0">
    <button
      id="sk-navbar-toggler"
      class="navbar-toggler"
      type="button"
      data-toggle="collapse"
      data-target="#navbarSupportedContent"
      aria-controls="navbarSupportedContent"
      aria-expanded="false"
      aria-label="Toggle navigation"
    >
      <span class="navbar-toggler-icon"></span>
    </button>

    <div class="sk-navbar-collapse collapse navbar-collapse" id="navbarSupportedContent">
      <ul class="navbar-nav mr-auto">
        <li class="nav-item">
          <a class="sk-nav-link nav-link" href="../index.html">Index</a>
        </li>
        <li class="nav-item">
          <a class="sk-nav-link nav-link" href="../installation.html">Install</a>
        </li>
        <!-- <li class="nav-item"> -->
        <!--   <a class="sk-nav-link nav-link" href="../auto_examples/index.html">Examples</a> -->
        <!-- </li> -->
        <li class="nav-item">
          <a class="sk-nav-link nav-link" href="../api.html">API</a>
        </li>
        <li class="nav-item">
          <a class="sk-nav-link nav-link" href="https://github.com/rlberry-py/rlberry-scool">github</a>
        </li>
        <!--
        <li class="nav-item dropdown nav-more-item-dropdown">
          <a class="sk-nav-link nav-link dropdown-toggle" href="#" id="navbarDropdown" role="button" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">More</a>
          <div class="dropdown-menu" aria-labelledby="navbarDropdown">
          </div>
        </li>-->
    </ul>
      <div id="searchbox" role="search">
          <div class="searchformwrapper">
            <form action="https://duckduckgo.com/">
            <input type="hidden" id="sites" name="sites" value="https://rlberry.readthedocs.io">
            <input type="search" placeholder="Search &hellip;" value="" name="q" />
            <input class="sk-search-text-btn" type="submit" value="Go" /></form>

          </div>
      </div>
    </div>
  </div>
</nav>
<div class="d-flex" id="sk-doc-wrapper">
    <input type="checkbox" name="sk-toggle-checkbox" id="sk-toggle-checkbox">
    <label id="sk-sidemenu-toggle" class="sk-btn-toggle-toc btn sk-btn-primary" for="sk-toggle-checkbox">Toggle Menu</label>
    <div id="sk-sidebar-wrapper" class="border-right">
      <div class="sk-sidebar-toc-wrapper">
        <div class="sk-sidebar-toc-logo">

        </div>
	<br>
            <div class="sk-sidebar-toc">
              <ul>
<li><a class="reference internal" href="#"><code class="xref py py-mod docutils literal notranslate"><span class="pre">rlberry_scool.agents.tabular_rl</span></code>.SARSAAgent</a><ul>
<li><a class="reference internal" href="#rlberry_scool.agents.tabular_rl.SARSAAgent"><code class="docutils literal notranslate"><span class="pre">SARSAAgent</span></code></a><ul>
<li><a class="reference internal" href="#rlberry_scool.agents.tabular_rl.SARSAAgent.eval"><code class="docutils literal notranslate"><span class="pre">SARSAAgent.eval()</span></code></a></li>
<li><a class="reference internal" href="#rlberry_scool.agents.tabular_rl.SARSAAgent.fit"><code class="docutils literal notranslate"><span class="pre">SARSAAgent.fit()</span></code></a></li>
<li><a class="reference internal" href="#rlberry_scool.agents.tabular_rl.SARSAAgent.get_params"><code class="docutils literal notranslate"><span class="pre">SARSAAgent.get_params()</span></code></a></li>
<li><a class="reference internal" href="#rlberry_scool.agents.tabular_rl.SARSAAgent.load"><code class="docutils literal notranslate"><span class="pre">SARSAAgent.load()</span></code></a></li>
<li><a class="reference internal" href="#rlberry_scool.agents.tabular_rl.SARSAAgent.output_dir"><code class="docutils literal notranslate"><span class="pre">SARSAAgent.output_dir</span></code></a></li>
<li><a class="reference internal" href="#rlberry_scool.agents.tabular_rl.SARSAAgent.policy"><code class="docutils literal notranslate"><span class="pre">SARSAAgent.policy()</span></code></a></li>
<li><a class="reference internal" href="#rlberry_scool.agents.tabular_rl.SARSAAgent.reseed"><code class="docutils literal notranslate"><span class="pre">SARSAAgent.reseed()</span></code></a></li>
<li><a class="reference internal" href="#rlberry_scool.agents.tabular_rl.SARSAAgent.rng"><code class="docutils literal notranslate"><span class="pre">SARSAAgent.rng</span></code></a></li>
<li><a class="reference internal" href="#rlberry_scool.agents.tabular_rl.SARSAAgent.sample_parameters"><code class="docutils literal notranslate"><span class="pre">SARSAAgent.sample_parameters()</span></code></a></li>
<li><a class="reference internal" href="#rlberry_scool.agents.tabular_rl.SARSAAgent.save"><code class="docutils literal notranslate"><span class="pre">SARSAAgent.save()</span></code></a></li>
<li><a class="reference internal" href="#rlberry_scool.agents.tabular_rl.SARSAAgent.set_writer"><code class="docutils literal notranslate"><span class="pre">SARSAAgent.set_writer()</span></code></a></li>
<li><a class="reference internal" href="#rlberry_scool.agents.tabular_rl.SARSAAgent.thread_shared_data"><code class="docutils literal notranslate"><span class="pre">SARSAAgent.thread_shared_data</span></code></a></li>
<li><a class="reference internal" href="#rlberry_scool.agents.tabular_rl.SARSAAgent.unique_id"><code class="docutils literal notranslate"><span class="pre">SARSAAgent.unique_id</span></code></a></li>
<li><a class="reference internal" href="#rlberry_scool.agents.tabular_rl.SARSAAgent.writer"><code class="docutils literal notranslate"><span class="pre">SARSAAgent.writer</span></code></a></li>
</ul>
</li>
</ul>
</li>
</ul>

            </div>
      </div>
    </div>
    <div id="sk-page-content-wrapper">
      <div class="sk-page-content container-fluid body px-md-3" role="main">
        
  <section id="rlberry-scool-agents-tabular-rl-sarsaagent">
<h1><code class="xref py py-mod docutils literal notranslate"><span class="pre">rlberry_scool.agents.tabular_rl</span></code>.SARSAAgent<a class="headerlink" href="#rlberry-scool-agents-tabular-rl-sarsaagent" title="Permalink to this heading">Â¶</a></h1>
<dl class="py class">
<dt class="sig sig-object py" id="rlberry_scool.agents.tabular_rl.SARSAAgent">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">rlberry_scool.agents.tabular_rl.</span></span><span class="sig-name descname"><span class="pre">SARSAAgent</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">env</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Env</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">Callable</span><span class="p"><span class="pre">[</span></span><span class="p"><span class="pre">[</span></span><span class="p"><span class="pre">...</span></span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Env</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Mapping</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Any</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">gamma</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">0.99</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">alpha</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">0.1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">exploration_type</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Literal</span><span class="p"><span class="pre">[</span></span><span class="s"><span class="pre">'epsilon'</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="s"><span class="pre">'boltzmann'</span></span><span class="p"><span class="pre">]</span></span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">exploration_rate</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/rlberry_scool/agents/tabular_rl/sarsa.html#SARSAAgent"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#rlberry_scool.agents.tabular_rl.SARSAAgent" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">AgentWithSimplePolicy</span></code></p>
<p>SARSA Agent.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>env: :class:`~rlberry.types.Env`</strong></dt><dd><p>Environment with discrete states and actions.</p>
</dd>
<dt><strong>gamma: float, default = 0.99</strong></dt><dd><p>Discount factor.</p>
</dd>
<dt><strong>alpha: float, default = 0.1</strong></dt><dd><p>Learning rate.</p>
</dd>
<dt><strong>exploration_type: {âepsilonâ, âboltzmannâ}, default: None</strong></dt><dd><p>If âepsilonâ: Epsilon-Greedy exploration.
If âboltzmannâ: Boltzmann exploration.
If None: No exploration.</p>
</dd>
<dt><strong>exploration_rate: float, default: None</strong></dt><dd><p>epsilon parameter for Epsilon-Greedy exploration or tau parameter for Boltzmann exploration.</p>
</dd>
<dt><strong>**kwargs</strong><span class="classifier">Keyword Arguments</span></dt><dd><p>Arguments to be passed to <cite>AgentWithSimplePolicy.__init__(self, env, **kwargs)</cite> (<code class="xref py py-class docutils literal notranslate"><span class="pre">AgentWithSimplePolicy</span></code>).</p>
</dd>
</dl>
</dd>
<dt class="field-even">Attributes<span class="colon">:</span></dt>
<dd class="field-even"><dl class="simple">
<dt><strong>Q</strong><span class="classifier">ndarray</span></dt><dd><p>2D array that stores the estimation ofexpected rewards for state-action pairs.</p>
</dd>
<dt><strong>Examples</strong></dt><dd></dd>
<dt><strong>âââ</strong></dt><dd></dd>
<dt><strong>&gt;&gt;&gt; from rlberry.envs import GridWorld</strong></dt><dd></dd>
<dt><strong>&gt;&gt;&gt;</strong></dt><dd></dd>
<dt><strong>&gt;&gt;&gt; env = GridWorld(walls=(), nrows=5, ncols=5)</strong></dt><dd></dd>
<dt><strong>&gt;&gt;&gt; agent = SARSAAgent()</strong></dt><dd></dd>
<dt><strong>&gt;&gt;&gt; agent.fit(budget=1000)</strong></dt><dd></dd>
<dt><strong>&gt;&gt;&gt; agent.policy(env.observation_space.sample())</strong></dt><dd></dd>
<dt><strong>&gt;&gt;&gt; agent.reset()</strong></dt><dd></dd>
</dl>
</dd>
</dl>
<p class="rubric">Methods</p>
<table class="autosummary longtable docutils align-default">
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="#rlberry_scool.agents.tabular_rl.SARSAAgent.eval" title="rlberry_scool.agents.tabular_rl.SARSAAgent.eval"><code class="xref py py-obj docutils literal notranslate"><span class="pre">eval</span></code></a>([eval_horizon,Â n_simulations,Â gamma])</p></td>
<td><p>Monte-Carlo policy evaluation <a class="reference internal" href="#r1abbd3a5fd70-1" id="id1">[1]</a> method to estimate the mean discounted reward using the current policy on the evaluation environment.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#rlberry_scool.agents.tabular_rl.SARSAAgent.fit" title="rlberry_scool.agents.tabular_rl.SARSAAgent.fit"><code class="xref py py-obj docutils literal notranslate"><span class="pre">fit</span></code></a>(budget,Â **kwargs)</p></td>
<td><p>Train the agent using the provided environment. Parameters ---------- budget: int     number of Q updates. <a href="#id2"><span class="problematic" id="id3">**</span></a>kwargs : Keyword Arguments     Extra arguments. Not used for this agent.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#rlberry_scool.agents.tabular_rl.SARSAAgent.get_params" title="rlberry_scool.agents.tabular_rl.SARSAAgent.get_params"><code class="xref py py-obj docutils literal notranslate"><span class="pre">get_params</span></code></a>([deep])</p></td>
<td><p>Get parameters for this agent.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#rlberry_scool.agents.tabular_rl.SARSAAgent.load" title="rlberry_scool.agents.tabular_rl.SARSAAgent.load"><code class="xref py py-obj docutils literal notranslate"><span class="pre">load</span></code></a>(filename,Â **kwargs)</p></td>
<td><p>Load agent object from filepath.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#rlberry_scool.agents.tabular_rl.SARSAAgent.policy" title="rlberry_scool.agents.tabular_rl.SARSAAgent.policy"><code class="xref py py-obj docutils literal notranslate"><span class="pre">policy</span></code></a>(observation)</p></td>
<td><p>Abstract method.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#rlberry_scool.agents.tabular_rl.SARSAAgent.reseed" title="rlberry_scool.agents.tabular_rl.SARSAAgent.reseed"><code class="xref py py-obj docutils literal notranslate"><span class="pre">reseed</span></code></a>([seed_seq])</p></td>
<td><p>Get new random number generator for the agent.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#rlberry_scool.agents.tabular_rl.SARSAAgent.sample_parameters" title="rlberry_scool.agents.tabular_rl.SARSAAgent.sample_parameters"><code class="xref py py-obj docutils literal notranslate"><span class="pre">sample_parameters</span></code></a>(trial)</p></td>
<td><p>Sample hyperparameters for hyperparam optimization using Optuna (<a class="reference external" href="https://optuna.org/">https://optuna.org/</a>)</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#rlberry_scool.agents.tabular_rl.SARSAAgent.save" title="rlberry_scool.agents.tabular_rl.SARSAAgent.save"><code class="xref py py-obj docutils literal notranslate"><span class="pre">save</span></code></a>(filename)</p></td>
<td><p>Save agent object.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#rlberry_scool.agents.tabular_rl.SARSAAgent.set_writer" title="rlberry_scool.agents.tabular_rl.SARSAAgent.set_writer"><code class="xref py py-obj docutils literal notranslate"><span class="pre">set_writer</span></code></a>(writer)</p></td>
<td><p>set self._writer.</p></td>
</tr>
</tbody>
</table>
<table class="docutils align-default">
<tbody>
<tr class="row-odd"><td><p><strong>get_action</strong></p></td>
<td></td>
</tr>
<tr class="row-even"><td><p><strong>reset</strong></p></td>
<td></td>
</tr>
</tbody>
</table>
<dl class="py method">
<dt class="sig sig-object py" id="rlberry_scool.agents.tabular_rl.SARSAAgent.eval">
<span class="sig-name descname"><span class="pre">eval</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">eval_horizon</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">100000</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_simulations</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">10</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">gamma</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1.0</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#rlberry_scool.agents.tabular_rl.SARSAAgent.eval" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Monte-Carlo policy evaluation <a class="reference internal" href="#r1abbd3a5fd70-1" id="id4">[1]</a> method to estimate the mean discounted reward using the current policy on the evaluation environment.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>eval_horizon</strong><span class="classifier">int, optional, default: 10**5</span></dt><dd><p>Maximum episode length, representing the horizon for each simulation.</p>
</dd>
<dt><strong>n_simulations</strong><span class="classifier">int, optional, default: 10</span></dt><dd><p>Number of Monte Carlo simulations to perform for the evaluation.</p>
</dd>
<dt><strong>gamma</strong><span class="classifier">float, optional, default: 1.0</span></dt><dd><p>Discount factor for future rewards.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><dl class="simple">
<dt>float</dt><dd><p>The mean value over ân_simulationsâ of the sum of rewards obtained in each simulation.</p>
</dd>
</dl>
</dd>
</dl>
<p class="rubric">References</p>
<div role="list" class="citation-list">
<div class="citation" id="r1abbd3a5fd70-1" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>1<span class="fn-bracket">]</span></span>
<span class="backrefs">(<a role="doc-backlink" href="#id1">1</a>,<a role="doc-backlink" href="#id4">2</a>)</span>
<p>Sutton, R. S., &amp; Barto, A. G. (2018). Reinforcement Learning: An Introduction.
MIT Press.</p>
</div>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="rlberry_scool.agents.tabular_rl.SARSAAgent.fit">
<span class="sig-name descname"><span class="pre">fit</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">budget</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/rlberry_scool/agents/tabular_rl/sarsa.html#SARSAAgent.fit"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#rlberry_scool.agents.tabular_rl.SARSAAgent.fit" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Train the agent using the provided environment.
Parameters
âââ-
budget: int</p>
<blockquote>
<div><p>number of Q updates.</p>
</div></blockquote>
<dl class="simple">
<dt><a href="#id6"><span class="problematic" id="id7">**</span></a>kwargs<span class="classifier">Keyword Arguments</span></dt><dd><p>Extra arguments. Not used for this agent.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="rlberry_scool.agents.tabular_rl.SARSAAgent.get_params">
<span class="sig-name descname"><span class="pre">get_params</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">deep</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#rlberry_scool.agents.tabular_rl.SARSAAgent.get_params" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Get parameters for this agent.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>deep</strong><span class="classifier">bool, default=True</span></dt><dd><p>If True, will return the parameters for this agent and
contained subobjects.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><dl class="simple">
<dt><strong>params</strong><span class="classifier">dict</span></dt><dd><p>Parameter names mapped to their values.</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="rlberry_scool.agents.tabular_rl.SARSAAgent.load">
<em class="property"><span class="pre">classmethod</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">load</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">filename</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#rlberry_scool.agents.tabular_rl.SARSAAgent.load" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Load agent object from filepath.</p>
<p>If overridden, save() method must also be overriden.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>filename: str</strong></dt><dd><p>Path to the object (pickle) to load.</p>
</dd>
<dt><strong>**kwargs: Keyword Arguments</strong></dt><dd><p>Arguments required by the __init__ method of the Agent subclass to load.</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="rlberry_scool.agents.tabular_rl.SARSAAgent.output_dir">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">output_dir</span></span><a class="headerlink" href="#rlberry_scool.agents.tabular_rl.SARSAAgent.output_dir" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Directory that the agent can use to store data.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="rlberry_scool.agents.tabular_rl.SARSAAgent.policy">
<span class="sig-name descname"><span class="pre">policy</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">observation</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/rlberry_scool/agents/tabular_rl/sarsa.html#SARSAAgent.policy"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#rlberry_scool.agents.tabular_rl.SARSAAgent.policy" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Abstract method.
The policy function takes an observation from the environment and returns an action.
The specific implementation of the policy function depends on the agentâs learning algorithm
or strategy, which can be deterministic or stochastic.
Parameters
âââ-
observation (any): An observation from the environment.
Returns
ââ-
action (any): The action to be taken based on the provided observation.
Notes
ââ
The data type of âobservationâ and âactionâ can vary depending on the specific agent
and the environment it interacts with.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="rlberry_scool.agents.tabular_rl.SARSAAgent.reseed">
<span class="sig-name descname"><span class="pre">reseed</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">seed_seq</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#rlberry_scool.agents.tabular_rl.SARSAAgent.reseed" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Get new random number generator for the agent.</p>
<dl class="field-list">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><dl>
<dt><strong>seed_seq</strong><span class="classifier"><code class="xref py py-class docutils literal notranslate"><span class="pre">numpy.random.SeedSequence</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">rlberry.seeding.seeder.Seeder</span></code> or int, default</span><span class="classifier">None</span></dt><dd><p>Seed sequence from which to spawn the random number generator.
If None, generate random seed.
If int, use as entropy for SeedSequence.
If seeder, use seeder.seed_seq</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="rlberry_scool.agents.tabular_rl.SARSAAgent.rng">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">rng</span></span><a class="headerlink" href="#rlberry_scool.agents.tabular_rl.SARSAAgent.rng" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Random number generator.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="rlberry_scool.agents.tabular_rl.SARSAAgent.sample_parameters">
<em class="property"><span class="pre">classmethod</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">sample_parameters</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">trial</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#rlberry_scool.agents.tabular_rl.SARSAAgent.sample_parameters" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Sample hyperparameters for hyperparam optimization using
Optuna (<a class="reference external" href="https://optuna.org/">https://optuna.org/</a>)</p>
<p>Note: only the kwargs sent to __init__ are optimized. Make sure to
include in the Agent constructor all âoptimizableâ parameters.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>trial: optuna.trial</strong></dt><dd></dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="rlberry_scool.agents.tabular_rl.SARSAAgent.save">
<span class="sig-name descname"><span class="pre">save</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">filename</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#rlberry_scool.agents.tabular_rl.SARSAAgent.save" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Save agent object. By default, the agent is pickled.</p>
<p>If overridden, the load() method must also be overriden.</p>
<p>Before saving, consider setting writer to None if it canât be pickled (tensorboard writers
keep references to files and cannot be pickled).</p>
<p>Note: dill[R504251f775f7-1]_ is used when pickle fails
(see <a class="reference external" href="https://stackoverflow.com/a/25353243">https://stackoverflow.com/a/25353243</a>, for instance).
Pickle is tried first, since it is faster.</p>
<dl class="field-list">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>filename: Path or str</strong></dt><dd><p>File in which to save the Agent.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><dl class="simple">
<dt>pathlib.Path</dt><dd><p>If save() is successful, a Path object corresponding to the filename is returned.
Otherwise, None is returned.</p>
</dd>
</dl>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>The returned filename might differ from the input filename: For instance,
..</p>
</div>
<dl class="simple">
<dt>the method can append the correct suffix to the name before saving.</dt><dd></dd>
</dl>
</dd>
</dl>
<p class="rubric">References</p>
<div role="list" class="citation-list">
<div class="citation" id="r504251f775f7-1" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>1<span class="fn-bracket">]</span></span>
<p><a class="reference external" href="https://github.com/uqfoundation/dill">https://github.com/uqfoundation/dill</a></p>
</div>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="rlberry_scool.agents.tabular_rl.SARSAAgent.set_writer">
<span class="sig-name descname"><span class="pre">set_writer</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">writer</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#rlberry_scool.agents.tabular_rl.SARSAAgent.set_writer" title="Permalink to this definition">Â¶</a></dt>
<dd><p>set self._writer. If is not None, add parameters values to writer.</p>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="rlberry_scool.agents.tabular_rl.SARSAAgent.thread_shared_data">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">thread_shared_data</span></span><a class="headerlink" href="#rlberry_scool.agents.tabular_rl.SARSAAgent.thread_shared_data" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Data shared by agent instances among different threads.</p>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="rlberry_scool.agents.tabular_rl.SARSAAgent.unique_id">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">unique_id</span></span><a class="headerlink" href="#rlberry_scool.agents.tabular_rl.SARSAAgent.unique_id" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Unique identifier for the agent instance. Can be used, for example, to create files/directories for the agent to log data safely.</p>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="rlberry_scool.agents.tabular_rl.SARSAAgent.writer">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">writer</span></span><a class="headerlink" href="#rlberry_scool.agents.tabular_rl.SARSAAgent.writer" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Writer object to log the output (e.g. tensorboard SummaryWriter)..</p>
</dd></dl>

</dd></dl>

<div class="clearer"></div></section>


      </div>
    <div class="container">
      <footer class="sk-content-footer">
            &copy; 2023, rlberry team.
          <a href="../_sources/generated/rlberry_scool.agents.tabular_rl.SARSAAgent.rst.txt" rel="nofollow">Show this page source</a>
      </footer>
    </div>
  </div>
</div>
<script src="../_static/js/vendor/bootstrap.min.js"></script>

<script>
    window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)};ga.l=+new Date;
    ga('create', 'UA-22606712-2', 'auto');
    ga('set', 'anonymizeIp', true);
    ga('send', 'pageview');
</script>
<script async src='https://www.google-analytics.com/analytics.js'></script>


<script>
$(document).ready(function() {
    /* Add a [>>>] button on the top-right corner of code samples to hide
     * the >>> and ... prompts and the output and thus make the code
     * copyable. */
    var div = $('.highlight-python .highlight,' +
                '.highlight-python3 .highlight,' +
                '.highlight-pycon .highlight,' +
		'.highlight-default .highlight')
    var pre = div.find('pre');

    // get the styles from the current theme
    pre.parent().parent().css('position', 'relative');
    var hide_text = 'Hide prompts and outputs';
    var show_text = 'Show prompts and outputs';

    // create and add the button to all the code blocks that contain >>>
    div.each(function(index) {
        var jthis = $(this);
        if (jthis.find('.gp').length > 0) {
            var button = $('<span class="copybutton">&gt;&gt;&gt;</span>');
            button.attr('title', hide_text);
            button.data('hidden', 'false');
            jthis.prepend(button);
        }
        // tracebacks (.gt) contain bare text elements that need to be
        // wrapped in a span to work with .nextUntil() (see later)
        jthis.find('pre:has(.gt)').contents().filter(function() {
            return ((this.nodeType == 3) && (this.data.trim().length > 0));
        }).wrap('<span>');
    });

    // define the behavior of the button when it's clicked
    $('.copybutton').click(function(e){
        e.preventDefault();
        var button = $(this);
        if (button.data('hidden') === 'false') {
            // hide the code output
            button.parent().find('.go, .gp, .gt').hide();
            button.next('pre').find('.gt').nextUntil('.gp, .go').css('visibility', 'hidden');
            button.css('text-decoration', 'line-through');
            button.attr('title', show_text);
            button.data('hidden', 'true');
        } else {
            // show the code output
            button.parent().find('.go, .gp, .gt').show();
            button.next('pre').find('.gt').nextUntil('.gp, .go').css('visibility', 'visible');
            button.css('text-decoration', 'none');
            button.attr('title', hide_text);
            button.data('hidden', 'false');
        }
    });

	/*** Add permalink buttons next to glossary terms ***/
	$('dl.glossary > dt[id]').append(function() {
		return ('<a class="headerlink" href="#' +
			    this.getAttribute('id') +
			    '" title="Permalink to this term">Â¶</a>');
	});
  /*** Hide navbar when scrolling down ***/
  // Returns true when headerlink target matches hash in url
  (function() {
    hashTargetOnTop = function() {
        var hash = window.location.hash;
        if ( hash.length < 2 ) { return false; }

        var target = document.getElementById( hash.slice(1) );
        if ( target === null ) { return false; }

        var top = target.getBoundingClientRect().top;
        return (top < 2) && (top > -2);
    };

    // Hide navbar on load if hash target is on top
    var navBar = document.getElementById("navbar");
    var navBarToggler = document.getElementById("sk-navbar-toggler");
    var navBarHeightHidden = "-" + navBar.getBoundingClientRect().height + "px";
    var $window = $(window);

    hideNavBar = function() {
        navBar.style.top = navBarHeightHidden;
    };

    showNavBar = function() {
        navBar.style.top = "0";
    }

    if (hashTargetOnTop()) {
        hideNavBar()
    }

    var prevScrollpos = window.pageYOffset;
    hideOnScroll = function(lastScrollTop) {
        if (($window.width() < 768) && (navBarToggler.getAttribute("aria-expanded") === 'true')) {
            return;
        }
        if (lastScrollTop > 2 && (prevScrollpos <= lastScrollTop) || hashTargetOnTop()){
            hideNavBar()
        } else {
            showNavBar()
        }
        prevScrollpos = lastScrollTop;
    };

    /*** high performance scroll event listener***/
    var raf = window.requestAnimationFrame ||
        window.webkitRequestAnimationFrame ||
        window.mozRequestAnimationFrame ||
        window.msRequestAnimationFrame ||
        window.oRequestAnimationFrame;
    var lastScrollTop = $window.scrollTop();

    if (raf) {
        loop();
    }

    function loop() {
        var scrollTop = $window.scrollTop();
        if (lastScrollTop === scrollTop) {
            raf(loop);
            return;
        } else {
            lastScrollTop = scrollTop;
            hideOnScroll(lastScrollTop);
            raf(loop);
        }
    }
  })();
});

</script>
    
<script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js"></script>
    
</body>
</html>